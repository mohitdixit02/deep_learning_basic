{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90dd3e66",
   "metadata": {},
   "source": [
    "Text Preprocessing Techniques - Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "28ae4239",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"The quick brown fox ðŸ¦Š jumps <p>over the lazy dog. its been such a long day, I realy knead a break </p> ðŸ˜´. Did you sea what happen'd at the store today? check out at: 'https://checknow.com' I cant beleive it, totaly wild! ðŸŽ‰\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d1ba1382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"the quick brown fox ðŸ¦Š jumps <p>over the lazy dog. its been such a long day, i realy knead a break </p> ðŸ˜´. did you sea what happen'd at the store today? check out at: 'https://checknow.com' i cant beleive it, totaly wild! ðŸŽ‰\""
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lowercasing\n",
    "data_1 = data.lower()\n",
    "data_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "f3387b24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"the quick brown fox ðŸ¦Š jumps over the lazy dog. its been such a long day, i realy knead a break  ðŸ˜´. did you sea what happen'd at the store today? check out at: 'https://checknow.com' i cant beleive it, totaly wild! ðŸŽ‰\""
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove HTML tags\n",
    "import re\n",
    "def remove_html_tags(text):\n",
    "    clean_text = re.sub(r'<.*?>', '', text)\n",
    "    return clean_text\n",
    "\n",
    "data_1 = remove_html_tags(data_1)\n",
    "data_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "d8df6bd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"the quick brown fox ðŸ¦Š jumps over the lazy dog. its been such a long day, i realy knead a break  ðŸ˜´. did you sea what happen'd at the store today? check out at: ' i cant beleive it, totaly wild! ðŸŽ‰\""
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove URLs\n",
    "def remove_urls(text):\n",
    "    clean_text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)\n",
    "    return clean_text\n",
    "\n",
    "data_1 = remove_urls(data_1)\n",
    "data_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "95758756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the quick brown fox ðŸ¦Š jumps over the lazy dog its been such a long day i realy knead a break  ðŸ˜´ did you sea what happend at the store today check out at  i cant beleive it totaly wild ðŸŽ‰'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove punctuation - Manually\n",
    "import string\n",
    "exclude = string.punctuation\n",
    "def remove_punctuation(text):\n",
    "    for char in exclude:\n",
    "        text = text.replace(char, '')\n",
    "    return text\n",
    "\n",
    "data_1 = remove_punctuation(data_1)\n",
    "data_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "68c29beb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the quick brown fox ðŸ¦Š jumps pover the lazy dog its been such a long day i realy knead a break p ðŸ˜´ did you sea what happend at the store today check out at httpschecknowcom i cant beleive it totaly wild ðŸŽ‰'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2 = data.lower()\n",
    "# Remove punctuation - Using translate (faster)\n",
    "def remv_punct_translate(text):\n",
    "    translator = str.maketrans('', '', exclude)\n",
    "    return text.translate(translator)\n",
    "\n",
    "remv_punct_translate(data_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "40fd9ff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't know what you are doing by the way\""
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chat Words Treatment\n",
    "chat_words_dict = {\n",
    "    \"u\": \"you\",\n",
    "    \"ur\": \"your\",\n",
    "    \"btw\": \"by the way\",\n",
    "    \"idk\": \"I don't know\",\n",
    "    \"imo\": \"in my opinion\",\n",
    "    \"brb\": \"be right back\",\n",
    "    \"r\": \"are\",\n",
    "}\n",
    "\n",
    "chat_word_text = \"idk what u r doing btw\"\n",
    "def replace_chat_words(text):\n",
    "    words = text.split()\n",
    "    new_words = [chat_words_dict.get(word, word) for word in words]\n",
    "    return ' '.join(new_words)\n",
    "\n",
    "replace_chat_words(chat_word_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "ab46b4d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I can believe it, total wild! I really head a break. Did you sea what happen'd at the store today?\""
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spelling Correction\n",
    "data_3 = \"I cant beleive it, totaly wild! I realy knead a break. Did you sea what happen'd at the store today?\"\n",
    "from textblob import TextBlob\n",
    "def correct_spelling(text):\n",
    "    blob = TextBlob(text)\n",
    "    return str(blob.correct())\n",
    "\n",
    "correct_spelling(data_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "3d73ea94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'quick brown fox ðŸ¦Š jumps lazy dog long day realy knead break ðŸ˜´ sea happend store today check cant beleive totaly wild ðŸŽ‰'"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing the Stop Words\n",
    "from nltk.corpus import stopwords\n",
    "stopwords_list = stopwords.words('english')\n",
    "def remove_stop_words(text):\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word not in stopwords_list]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "remove_stop_words(data_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "419262d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the quick brown fox  jumps over the lazy dog its been such a long day i realy knead a break   did you sea what happend at the store today check out at  i cant beleive it totaly wild '"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# handling Emojis - remove\n",
    "import emoji\n",
    "def remove_emojis(text):\n",
    "    removed_emoji_text = [char for char in text if char not in emoji.EMOJI_DATA]\n",
    "    removed_emoji_text = ''.join(removed_emoji_text)\n",
    "    return removed_emoji_text\n",
    "\n",
    "remove_emojis(data_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "5a75d5ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the quick brown fox :fox: jumps over the lazy dog its been such a long day i realy knead a break  :sleeping_face: did you sea what happend at the store today check out at  i cant beleive it totaly wild :party_popper:'"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# handling Emojis - convert to text\n",
    "def emojis_to_text(text):\n",
    "    return emoji.demojize(text)\n",
    "\n",
    "emojis_to_text(data_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "61cd504e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The quick brown fox ðŸ¦Š jumps <p>over the lazy dog.',\n",
       " 'its been such a long day, I realy knead a break </p> ðŸ˜´.',\n",
       " \"Did you sea what happen'd at the store today?\",\n",
       " \"check out at: 'https://checknow.com' I cant beleive it, totaly wild!\",\n",
       " 'ðŸŽ‰']"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sentence Tokenization\n",
    "data_4 = data\n",
    "from nltk.tokenize import sent_tokenize\n",
    "sentences = sent_tokenize(data_4)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "4efec867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'quick',\n",
       " 'brown',\n",
       " 'fox',\n",
       " 'ðŸ¦Š',\n",
       " 'jumps',\n",
       " '<',\n",
       " 'p',\n",
       " '>',\n",
       " 'over',\n",
       " 'the',\n",
       " 'lazy',\n",
       " 'dog',\n",
       " '.',\n",
       " 'its',\n",
       " 'been',\n",
       " 'such',\n",
       " 'a',\n",
       " 'long',\n",
       " 'day',\n",
       " ',',\n",
       " 'I',\n",
       " 'realy',\n",
       " 'knead',\n",
       " 'a',\n",
       " 'break',\n",
       " '<',\n",
       " '/p',\n",
       " '>',\n",
       " 'ðŸ˜´',\n",
       " '.',\n",
       " 'Did',\n",
       " 'you',\n",
       " 'sea',\n",
       " 'what',\n",
       " 'happen',\n",
       " \"'d\",\n",
       " 'at',\n",
       " 'the',\n",
       " 'store',\n",
       " 'today',\n",
       " '?',\n",
       " 'check',\n",
       " 'out',\n",
       " 'at',\n",
       " ':',\n",
       " \"'https\",\n",
       " ':',\n",
       " '//checknow.com',\n",
       " \"'\",\n",
       " 'I',\n",
       " 'cant',\n",
       " 'beleive',\n",
       " 'it',\n",
       " ',',\n",
       " 'totaly',\n",
       " 'wild',\n",
       " '!',\n",
       " 'ðŸŽ‰']"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Word Tokenization\n",
    "from nltk.tokenize import word_tokenize\n",
    "words = word_tokenize(data_4)\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "931c5286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'quick',\n",
       " 'brown',\n",
       " 'fox',\n",
       " 'ðŸ¦Š',\n",
       " 'jump',\n",
       " '<',\n",
       " 'p',\n",
       " '>',\n",
       " 'over',\n",
       " 'the',\n",
       " 'lazi',\n",
       " 'dog',\n",
       " '.',\n",
       " 'it',\n",
       " 'been',\n",
       " 'such',\n",
       " 'a',\n",
       " 'long',\n",
       " 'day',\n",
       " ',',\n",
       " 'i',\n",
       " 'reali',\n",
       " 'knead',\n",
       " 'a',\n",
       " 'break',\n",
       " '<',\n",
       " '/p',\n",
       " '>',\n",
       " 'ðŸ˜´',\n",
       " '.',\n",
       " 'did',\n",
       " 'you',\n",
       " 'sea',\n",
       " 'what',\n",
       " 'happen',\n",
       " \"'d\",\n",
       " 'at',\n",
       " 'the',\n",
       " 'store',\n",
       " 'today',\n",
       " '?',\n",
       " 'check',\n",
       " 'out',\n",
       " 'at',\n",
       " ':',\n",
       " \"'http\",\n",
       " ':',\n",
       " '//checknow.com',\n",
       " \"'\",\n",
       " 'i',\n",
       " 'cant',\n",
       " 'beleiv',\n",
       " 'it',\n",
       " ',',\n",
       " 'totali',\n",
       " 'wild',\n",
       " '!',\n",
       " 'ðŸŽ‰']"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stemming\n",
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "stemmed_words = [ps.stem(word) for word in words]\n",
    "stemmed_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "b75b4bd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'quick',\n",
       " 'brown',\n",
       " 'fox',\n",
       " 'ðŸ¦Š',\n",
       " 'jump',\n",
       " '<',\n",
       " 'p',\n",
       " '>',\n",
       " 'over',\n",
       " 'the',\n",
       " 'lazy',\n",
       " 'dog',\n",
       " '.',\n",
       " 'it',\n",
       " 'been',\n",
       " 'such',\n",
       " 'a',\n",
       " 'long',\n",
       " 'day',\n",
       " ',',\n",
       " 'I',\n",
       " 'realy',\n",
       " 'knead',\n",
       " 'a',\n",
       " 'break',\n",
       " '<',\n",
       " '/p',\n",
       " '>',\n",
       " 'ðŸ˜´',\n",
       " '.',\n",
       " 'Did',\n",
       " 'you',\n",
       " 'sea',\n",
       " 'what',\n",
       " 'happen',\n",
       " \"'d\",\n",
       " 'at',\n",
       " 'the',\n",
       " 'store',\n",
       " 'today',\n",
       " '?',\n",
       " 'check',\n",
       " 'out',\n",
       " 'at',\n",
       " ':',\n",
       " \"'https\",\n",
       " ':',\n",
       " '//checknow.com',\n",
       " \"'\",\n",
       " 'I',\n",
       " 'cant',\n",
       " 'beleive',\n",
       " 'it',\n",
       " ',',\n",
       " 'totaly',\n",
       " 'wild',\n",
       " '!',\n",
       " 'ðŸŽ‰']"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lemmatization\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wnl = WordNetLemmatizer()\n",
    "lemmatized_words = [wnl.lemmatize(word) for word in words]\n",
    "lemmatized_words"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
